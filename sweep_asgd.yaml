program: experiments.sweep_experiment
method: random
project: ResNet18Optimizing
entity: kn-bmi
metric:
  goal: minimize
  name: val_loss
parameters:
  optimizer:
    value: 'asgd'
  
  lr_scheduler:
    values: [
      ['multiplicative_lr', 0.99],
      ['multiplicative_lr', 0.95],
      ['multiplicative_lr', 0.90],
      ['multiplicative_lr', 0.99],
      ['multiplicative_lr', 0.95],
      ['multiplicative_lr', 0.90],
      ['cosine_lr', 20],
      ['cosine_lr', 40],
      ['cosine_lr', 60],
      ['cosine_lr', 20],
      ['cosine_lr', 40],
      ['cosine_lr', 60],
      ['cosine_warm_lr', 4, 1],
      ['cosine_warm_lr', 6, 1],
      ['cosine_warm_lr', 8, 1],
      ['cosine_warm_lr', 4, 2],
      ['cosine_warm_lr', 6, 2],
      ['cosine_warm_lr', 8, 2],
      ['None'],
      ['None'],
      ['None'],
      ['None'],
      ['None'],
      ['None']
    ]

  alpha_asgd:
    values: [0.5, 0.75, 0.9]
  
  lambda_asgd:
    values: [1e-4, 1e-5, 1e-6]
  
  t0_asgd:
    values: [1e7, 1e6, 1e5]

  learning_rate:
    values: [1e-1, 1e-2, 1e-3, 1e-4]
  
  weight_decay:
    values: [1e-6, 1e-7, 0]

  batch_size:
    values: [32, 64]

  weight_0:
    distribution: normal
    mu: 1
    sigma: 0.1

  weight_1:
    distribution: normal
    mu: 1.5
    sigma: 0.2

  weight_2:
    distribution: normal
    mu: 2.65
    sigma: 0.28

  weight_3:
    distribution: normal
    mu: 2
    sigma: 0.21

command:
  - ${env}
  - PL_TORCH_DISTRIBUTED_BACKEND=gloo poetry run python3 -m
  - ${program}
  - ${args}
